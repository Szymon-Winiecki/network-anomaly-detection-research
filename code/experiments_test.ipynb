{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('./datasets')\n",
    "sys.path.append('./models')\n",
    "sys.path.append('./utils')\n",
    "sys.path.append('./callbacks')\n",
    "sys.path.append('./visualization')\n",
    "\n",
    "from utils.experiment_utils import CSVLogger, run_experiment, load_dataset, load_dataset_folds, run_cross_validation\n",
    "\n",
    "from callbacks.LatentSpacePlotter import LatentSpacePlotter\n",
    "from callbacks.LatentSpaceEvolutionPlotter import LatentSpaceEvolutionPlotter\n",
    "\n",
    "from visualization.metric_plots import plot_ROC_curve\n",
    "\n",
    "from models.AE import AE\n",
    "from models.BAE import BAE\n",
    "from models.SAE import SAE\n",
    "from models.CAE import CAE\n",
    "from models.KSAE import KSAE\n",
    "from models.CAEAA import CAEAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median').set_output(transform='pandas')),\n",
    "    ('scaler', StandardScaler().set_output(transform='pandas'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDDCUP99 = load_dataset(\"KDDCUP99\", \"../data/KDDCUP99/preprocessed/\")\n",
    "# CICIDS2017 = load_dataset(\"CICIDS2017\", \"../data/CIC-IDS2017/preprocessed/\")\n",
    "# UNSWNB15 = load_dataset(\"UNSW-NB15\", \"../data/UNSW-NB15/preprocessed/\")\n",
    "# CTU13_08 = load_dataset(\"CTU-13_08\", \"../data/CTU-13/preprocessed/08\", pipeline=pipeline)\n",
    "# CTU13_09 = load_dataset(\"CTU-13_09\", \"../data/CTU-13/preprocessed/09\", pipeline=pipeline)\n",
    "# CTU13_10 = load_dataset(\"CTU-13_10\", \"../data/CTU-13/preprocessed/10\", pipeline=pipeline)\n",
    "# CTU13_13 = load_dataset(\"CTU-13_13\", \"../data/CTU-13/preprocessed/13\", pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDDCUP99_folds = load_dataset_folds(\"KDDCUP99\", \"../data/KDDCUP99/preprocessed/\", kfolds=3, pipeline=pipeline)\n",
    "UNSWNB15_folds = load_dataset_folds(\"UNSW-NB15\", \"../data/UNSW-NB15/preprocessed/\", kfolds=3, pipeline=pipeline)\n",
    "CTU13_08_folds = load_dataset_folds(\"CTU-13_08\", \"../data/CTU-13/preprocessed/08\", kfolds=3, pipeline=pipeline)\n",
    "CTU13_09_folds = load_dataset_folds(\"CTU-13_09\", \"../data/CTU-13/preprocessed/09\", kfolds=3, pipeline=pipeline)\n",
    "CTU13_10_folds = load_dataset_folds(\"CTU-13_10\", \"../data/CTU-13/preprocessed/10\", kfolds=3, pipeline=pipeline)\n",
    "CTU13_13_folds = load_dataset_folds(\"CTU-13_13\", \"../data/CTU-13/preprocessed/13\", kfolds=3, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KDDCUP99_folds\n",
    "model = AE(\n",
    "                        input_size=dataset[0]['train'].x.shape[1],\n",
    "                        hidden_sizes=[256, 64, 8],\n",
    "                        batch_norm=True,\n",
    "                        initial_lr=0.01,\n",
    "                        optimizer=\"Adadelta\",\n",
    "                        optimizer_params={'rho': 0.9},\n",
    "                        scheduler=\"StepLR\",\n",
    "                        scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                        )\n",
    "\n",
    "run_experiment(model, \n",
    "               dataset[0], \n",
    "               max_epochs=1, \n",
    "               trainer_callbacks=[\n",
    "                    # LatentSpacePlotter(\"../out/figures/test/latent_space_plotter\", \"test\", dataset[0]['train'].name, plot_epochs=[39]),\n",
    "                    # LatentSpaceEvolutionPlotter(\"../out/figures/test/latent_space_evolution_plotter\", \"test\", dataset[0]['train'].name, plot_epochs=[0, 19, 39])\n",
    "                   ]\n",
    "               )\n",
    "\n",
    "# fpr, tpr, auc, cluster_sizes = model.calc_ROC(dataset[0]['val'])\n",
    "\n",
    "# plot_ROC_curve(fpr, tpr, auc, cluster_sizes, model.name, dataset[0]['train'].name, \"../out/figures/test/roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BAE(birch_threshold=0.1,\n",
    "            birch_branching_factor=50,\n",
    "            birch_fit_quantile=0.9,\n",
    "            birch_n_clusters=2,\n",
    "            birch_fit_sample_size=15000,\n",
    "            base_model=AE,\n",
    "            input_size=dataset[0]['train'].x.shape[1],\n",
    "            hidden_sizes=[128, 64, 8],\n",
    "            batch_norm=True,\n",
    "            initial_lr=0.01,\n",
    "            optimizer=\"Adadelta\",\n",
    "            optimizer_params={'rho': 0.9},\n",
    "            scheduler=\"StepLR\",\n",
    "            scheduler_params={'step_size':20, 'gamma':0.5})\n",
    "\n",
    "run_experiment(model, dataset[0], max_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger(\"../out/logs/test/threshold/ksae.csv\")\n",
    "\n",
    "threshold_quantiles = np.arange(0.8, 1.0, 0.05).tolist()\n",
    "\n",
    "for threshold_quantile in threshold_quantiles:\n",
    "    metrics = model.test_threshold_quantile(dataset[0]['train'], dataset[0]['val'], threshold_quantile)\n",
    "    metrics['quantile'] = threshold_quantile\n",
    "    logger.log(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CAE threshold tuning\n",
    "\n",
    "fold = 1\n",
    "\n",
    "datasets = [KDDCUP99_folds[fold], UNSWNB15_folds[fold], CTU13_08_folds[fold], CTU13_09_folds[fold], CTU13_10_folds[fold], CTU13_13_folds[fold]]\n",
    "nums_clusters = [2, 4, 2, 2, 2, 2]\n",
    "\n",
    "hidden_sizes = [[256, 64]]\n",
    "initial_lrs = [5e-2]\n",
    "\n",
    "threshold_quantiles = [1.0]\n",
    "# threshold_quantiles = np.arange(0.9, 1.005, 0.005).tolist()\n",
    "\n",
    "\n",
    "for dataset, num_clusters in zip(datasets, nums_clusters):\n",
    "    for initial_lr in initial_lrs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            input_size = dataset['train'][0][0].shape[0]\n",
    "            hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "            model = CAE(\n",
    "                    input_size=input_size, \n",
    "                    hidden_sizes=hidden_size,\n",
    "                    batch_norm=True,\n",
    "                    initial_lr=initial_lr,\n",
    "                    optimizer=\"Adadelta\",\n",
    "                    optimizer_params={'rho': 0.9},\n",
    "                    scheduler=\"StepLR\",\n",
    "                    scheduler_params={'step_size':30, 'gamma':0.5},\n",
    "                    num_clusters=num_clusters\n",
    "                    )\n",
    "\n",
    "            result = run_experiment(\n",
    "                model=model,\n",
    "                dataset=dataset,\n",
    "                max_epochs=70,\n",
    "                experiment_name=f\"CAE tuning {dataset['train'].name} {hidden_size}\",\n",
    "                run_name=f\"lr={initial_lr} num_clusters={num_clusters}\",\n",
    "                save_model=False\n",
    "            )\n",
    "\n",
    "            logger = CSVLogger(f\"../out/logs/threshold/CAE_{dataset['train'].name}.csv\")\n",
    "\n",
    "            for threshold_quantile in threshold_quantiles:\n",
    "                metrics = model.test_threshold_quantile(dataset['train'], dataset['val'], threshold_quantile)\n",
    "                metrics['quantile'] = threshold_quantile\n",
    "                logger.log(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAE SVM threshold tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds[fold], UNSWNB15_folds[fold], CTU13_08_folds[fold], CTU13_09_folds[fold], CTU13_10_folds[fold], CTU13_13_folds[fold]]\n",
    "\n",
    "hidden_sizes = [[256, 64]]\n",
    "initial_lrs = [1e-2]\n",
    "\n",
    "threshold_quantiles = np.arange(0.95, 1.005, 0.005).tolist()\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for initial_lr in initial_lrs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            input_size = dataset['train'][0][0].shape[0]\n",
    "            hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "            model = SAE(\n",
    "                    input_size=input_size, \n",
    "                    hidden_sizes=hidden_size,\n",
    "                    batch_norm=True,\n",
    "                    initial_lr=initial_lr,\n",
    "                    optimizer=\"Adadelta\",\n",
    "                    optimizer_params={'rho': 0.9},\n",
    "                    scheduler=\"StepLR\",\n",
    "                    scheduler_params={'step_size':30, 'gamma':0.5},\n",
    "                    occ_algorithm='svm',\n",
    "                    occ_fit_sample_size=15000,\n",
    "                    fit_occ_once=True,\n",
    "                    lmb=50,\n",
    "                    nu=0.05,\n",
    "                    )\n",
    "\n",
    "            result = run_experiment(\n",
    "                model=model,\n",
    "                dataset=dataset,\n",
    "                max_epochs=80,\n",
    "                experiment_name=f\"SAE tuning {dataset['train'].name} {hidden_size}\",\n",
    "                run_name=f\"lr={initial_lr}\",\n",
    "                save_model=False\n",
    "            )\n",
    "\n",
    "            logger = CSVLogger(f\"../out/logs/threshold/SAE_svm_{dataset['train'].name}.csv\")\n",
    "\n",
    "            for threshold_quantile in threshold_quantiles:\n",
    "                metrics = model.test_threshold_quantile(dataset['train'], dataset['val'], threshold_quantile)\n",
    "                metrics['quantile'] = threshold_quantile\n",
    "                logger.log(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  AE threshold tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds[0], UNSWNB15_folds[0], CTU13_08_folds[0], CTU13_09_folds[0], CTU13_10_folds[0], CTU13_13_folds[0]]\n",
    "\n",
    "hidden_sizes = [[256, 64]]\n",
    "initial_lrs = [1e-1]\n",
    "\n",
    "threshold_quantiles = [1.0]\n",
    "# threshold_quantiles = np.arange(0.9, 1.0, 0.005).tolist()\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for initial_lr in initial_lrs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            input_size = dataset['train'][0][0].shape[0]\n",
    "            hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "            model = AE(\n",
    "                    input_size=input_size, \n",
    "                    hidden_sizes=hidden_size,\n",
    "                    batch_norm=True,\n",
    "                    initial_lr=initial_lr,\n",
    "                    optimizer=\"Adadelta\",\n",
    "                    optimizer_params={'rho': 0.9},\n",
    "                    scheduler=\"StepLR\",\n",
    "                    scheduler_params={'step_size':30, 'gamma':0.5},\n",
    "                    )\n",
    "\n",
    "            result = run_experiment(\n",
    "                model=model,\n",
    "                dataset=dataset,\n",
    "                max_epochs=70,\n",
    "                experiment_name=f\"AE tuning {dataset['train'].name} {hidden_size}\",\n",
    "                run_name=f\"lr={initial_lr}\",\n",
    "                save_model=False\n",
    "            )\n",
    "\n",
    "            logger = CSVLogger(f\"../out/logs/threshold/AE_svm_{dataset['train'].name}.csv\")\n",
    "\n",
    "            for threshold_quantile in threshold_quantiles:\n",
    "                metrics = model.test_threshold_quantile(dataset['train'], dataset['val'], threshold_quantile)\n",
    "                metrics['quantile'] = threshold_quantile\n",
    "                logger.log(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/threshold/AE_svm_{dataset['train'].name}.csv\")\n",
    "    print(f\"Results for {dataset['train'].name}:\")\n",
    "    print(logger.df[['quantile', 'test_mcc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  AE tuning\n",
    "\n",
    "datasets = [CTU13_09_folds, CTU13_10_folds, CTU13_13_folds]\n",
    "\n",
    "hidden_sizes = [[64, 32], [32, 16]]\n",
    "initial_lrs = [1e-1]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/AE_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for hidden_size in hidden_sizes:\n",
    "        input_size = dataset[0]['train'][0][0].shape[0]\n",
    "        hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "        model = AE(\n",
    "                input_size=input_size, \n",
    "                hidden_sizes=hidden_size,\n",
    "                batch_norm=True,\n",
    "                initial_lr=1e-1,\n",
    "                optimizer=\"Adadelta\",\n",
    "                optimizer_params={'rho': 0.9},\n",
    "                scheduler=\"StepLR\",\n",
    "                scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                threshold_quantile=0.95,\n",
    "                )\n",
    "\n",
    "        result, _ = run_cross_validation(\n",
    "            model=model,\n",
    "            dataset_folds=dataset,\n",
    "            max_epochs=40,\n",
    "            experiment_name=f\"AE th tuning {dataset[0]['train'].name}\",\n",
    "            run_name=f\"{hidden_size}\",\n",
    "            save_model=False\n",
    "        )\n",
    "\n",
    "        logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAE cen tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds, UNSWNB15_folds, CTU13_08_folds, CTU13_09_folds, CTU13_10_folds, CTU13_13_folds]\n",
    "\n",
    "hidden_sizes = [[256, 64]]\n",
    "initial_lrs = [1e-2]\n",
    "lmbs = [1, 10]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/SAE_cen_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for lmb in lmbs:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                model = SAE(\n",
    "                        input_size=input_size, \n",
    "                        hidden_sizes=hidden_size,\n",
    "                        batch_norm=True,\n",
    "                        initial_lr=initial_lr,\n",
    "                        optimizer=\"Adadelta\",\n",
    "                        optimizer_params={'rho': 0.9},\n",
    "                        scheduler=\"StepLR\",\n",
    "                        scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                        lmb=lmb,\n",
    "                        occ_algorithm='centroid',\n",
    "                        fit_occ_once=True,\n",
    "                        occ_fit_sample_size=15000,\n",
    "                        )\n",
    "\n",
    "                result, _ = run_cross_validation(\n",
    "                    model=model,\n",
    "                    dataset_folds=dataset,\n",
    "                    max_epochs=10,\n",
    "                    experiment_name=f\"SAE cen tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                    run_name=f\"lr={initial_lr} lmb={lmb}\",\n",
    "                    save_model=False\n",
    "                )\n",
    "    \n",
    "                logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAE lof tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds, UNSWNB15_folds, CTU13_08_folds, CTU13_09_folds, CTU13_10_folds, CTU13_13_folds]\n",
    "\n",
    "hidden_sizes = [128, 64]\n",
    "initial_lrs = [1e-3]\n",
    "lmbs = [50]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/SAE_lof_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for lmb in lmbs:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                model = SAE(\n",
    "                        input_size=input_size, \n",
    "                        hidden_sizes=hidden_size,\n",
    "                        batch_norm=True,\n",
    "                        initial_lr=initial_lr,\n",
    "                        optimizer=\"Adadelta\",\n",
    "                        optimizer_params={'rho': 0.9},\n",
    "                        scheduler=\"StepLR\",\n",
    "                        scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                        lmb=lmb,\n",
    "                        occ_algorithm='lof',\n",
    "                        fit_occ_once=True,\n",
    "                        occ_fit_sample_size=15000,\n",
    "                        n_neighbors=200,\n",
    "                        )\n",
    "\n",
    "                result, _ = run_cross_validation(\n",
    "                    model=model,\n",
    "                    dataset_folds=dataset,\n",
    "                    max_epochs=30,\n",
    "                    experiment_name=f\"SAE lof tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                    run_name=f\"lr={initial_lr} lmb={lmb}\",\n",
    "                    save_model=False\n",
    "                )\n",
    "    \n",
    "                logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAE svm tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds, UNSWNB15_folds, CTU13_13_folds, CTU13_08_folds, CTU13_09_folds, CTU13_10_folds]\n",
    "\n",
    "hidden_sizes = [[64, 32], [32, 16]]\n",
    "initial_lrs = [1e-2]\n",
    "lmbs = [50]\n",
    "nus = [0.05]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/SAE_svm_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for lmb in lmbs:\n",
    "            for nu in nus:\n",
    "                for hidden_size in hidden_sizes:\n",
    "                    input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                    hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                    model = SAE(\n",
    "                            input_size=input_size, \n",
    "                            hidden_sizes=hidden_size,\n",
    "                            batch_norm=True,\n",
    "                            initial_lr=initial_lr,\n",
    "                            optimizer=\"Adadelta\",\n",
    "                            optimizer_params={'rho': 0.9},\n",
    "                            scheduler=\"StepLR\",\n",
    "                            scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                            lmb=lmb,\n",
    "                            occ_algorithm='svm',\n",
    "                            nu=nu,\n",
    "                            fit_occ_once=True,\n",
    "                            occ_fit_sample_size=15000,\n",
    "                            )\n",
    "\n",
    "                    result, _ = run_cross_validation(\n",
    "                        model=model,\n",
    "                        dataset_folds=dataset,\n",
    "                        max_epochs=40,\n",
    "                        experiment_name=f\"SAE svm tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                        run_name=f\"lr={initial_lr} lmb={lmb}, nu={nu}\",\n",
    "                        save_model=False\n",
    "                    )\n",
    "        \n",
    "                    logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CAE tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds, UNSWNB15_folds]\n",
    "\n",
    "hidden_sizes = [[256, 64]]\n",
    "initial_lrs = [5e-2]\n",
    "nums_clusters = [2, 3, 4]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/CAE_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for num_clusters in nums_clusters:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                model = CAE(\n",
    "                        input_size=input_size, \n",
    "                        hidden_sizes=hidden_size,\n",
    "                        batch_norm=True,\n",
    "                        initial_lr=initial_lr,\n",
    "                        optimizer=\"Adadelta\",\n",
    "                        optimizer_params={'rho': 0.9},\n",
    "                        scheduler=\"StepLR\",\n",
    "                        scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                        num_clusters=num_clusters\n",
    "                        )\n",
    "\n",
    "                result, _ = run_cross_validation(\n",
    "                    model=model,\n",
    "                    dataset_folds=dataset,\n",
    "                    max_epochs=40,\n",
    "                    experiment_name=f\"CAE tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                    run_name=f\"lr={initial_lr} num_clusters={num_clusters}\",\n",
    "                    save_model=False\n",
    "                )\n",
    "    \n",
    "                logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  KSAE SEP svm tuning\n",
    "\n",
    "datasets = [KDDCUP99_folds, UNSWNB15_folds, CTU13_10_folds]\n",
    "\n",
    "hidden_sizes = [[256, 64, 24]]\n",
    "initial_lrs = [1e-2]\n",
    "lmbs = [50]\n",
    "nus = [0.05]\n",
    "nums_clusters = [2, 3, 4]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/KSAE_svm_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for lmb in lmbs:\n",
    "            for nu in nus:\n",
    "                for num_clusters in nums_clusters:\n",
    "                    for hidden_size in hidden_sizes:\n",
    "                        input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                        hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                        model = KSAE(\n",
    "                                kmeans_n_clusters=num_clusters,\n",
    "                                kmeans_fit_quantile=0.9,\n",
    "                                kmeans_fit_sample_size=15000,\n",
    "                                base_model=SAE,\n",
    "                                input_size=input_size, \n",
    "                                hidden_sizes=hidden_size,\n",
    "                                batch_norm=True,\n",
    "                                initial_lr=initial_lr,\n",
    "                                optimizer=\"Adadelta\",\n",
    "                                optimizer_params={'rho': 0.9},\n",
    "                                scheduler=\"StepLR\",\n",
    "                                scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                                lmb=lmb,\n",
    "                                occ_algorithm='svm',\n",
    "                                nu=nu,\n",
    "                                fit_occ_once=True,\n",
    "                                occ_fit_sample_size=15000,\n",
    "                                )\n",
    "\n",
    "                        result, _ = run_cross_validation(\n",
    "                            model=model,\n",
    "                            dataset_folds=dataset,\n",
    "                            max_epochs=40,\n",
    "                            experiment_name=f\"KSAE svm tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                            run_name=f\"lr={initial_lr} lmb={lmb}, nu={nu}\",\n",
    "                            save_model=False,\n",
    "                            fit_params={'adjust_epochs': True}\n",
    "                        )\n",
    "            \n",
    "                        logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  KSAE SEP cen tuning\n",
    "\n",
    "datasets = [UNSWNB15_folds, CTU13_08_folds, CTU13_09_folds, CTU13_10_folds, CTU13_13_folds]\n",
    "# datasets = [UNSWNB15_folds]\n",
    "\n",
    "hidden_sizes = [[128, 64]]\n",
    "initial_lrs = [1e-2]\n",
    "lmbs = [50]\n",
    "nums_clusters = [2, 3, 4]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/KSAE_cen_adj_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for lmb in lmbs:\n",
    "            for num_clusters in nums_clusters:\n",
    "                for hidden_size in hidden_sizes:\n",
    "                    input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                    hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                    model = KSAE(\n",
    "                            kmeans_n_clusters=num_clusters,\n",
    "                            kmeans_fit_quantile=0.9,\n",
    "                            kmeans_fit_sample_size=15000,\n",
    "                            base_model=SAE,\n",
    "                            input_size=input_size, \n",
    "                            hidden_sizes=hidden_size,\n",
    "                            batch_norm=True,\n",
    "                            initial_lr=initial_lr,\n",
    "                            optimizer=\"Adadelta\",\n",
    "                            optimizer_params={'rho': 0.9},\n",
    "                            scheduler=\"StepLR\",\n",
    "                            scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                            lmb=lmb,\n",
    "                            occ_algorithm='centroid',\n",
    "                            fit_occ_once=True,\n",
    "                            occ_fit_sample_size=15000,\n",
    "                            )\n",
    "\n",
    "                    result, _ = run_cross_validation(\n",
    "                        model=model,\n",
    "                        dataset_folds=dataset,\n",
    "                        max_epochs=15,\n",
    "                        experiment_name=f\"KSAE cen adj4 tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                        run_name=f\"lr={initial_lr} lmb={lmb}\",\n",
    "                        save_model=False,\n",
    "                        fit_params={'adjust_epochs': True},\n",
    "                    )\n",
    "        \n",
    "                    logger.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  BAE tuning\n",
    "\n",
    "# datasets = [KDDCUP99_folds, UNSWNB15_folds, CTU13_09_folds]\n",
    "datasets = [UNSWNB15_folds]\n",
    "\n",
    "hidden_sizes = [[256, 64, 24]]\n",
    "initial_lrs = [1e-1]\n",
    "nums_clusters = [2]\n",
    "\n",
    "for dataset in datasets:\n",
    "    logger = CSVLogger(f\"../out/logs/BAE_tuning_{dataset[0]['train'].name}.csv\")\n",
    "    for initial_lr in initial_lrs:\n",
    "        for num_clusters in nums_clusters:\n",
    "            for hidden_size in hidden_sizes:\n",
    "                input_size = dataset[0]['train'][0][0].shape[0]\n",
    "                hidden_size = hidden_size + [int(input_size ** 0.5) + 1]  \n",
    "                model = BAE(\n",
    "                    birch_branching_factor=50,\n",
    "                    birch_threshold=0.1,\n",
    "                        birch_n_clusters=num_clusters,\n",
    "                        birch_fit_quantile=0.9,\n",
    "                        birch_fit_sample_size=15000,\n",
    "                        base_model=SAE,\n",
    "                        input_size=input_size, \n",
    "                        hidden_sizes=hidden_size,\n",
    "                        batch_norm=True,\n",
    "                        initial_lr=initial_lr,\n",
    "                        optimizer=\"Adadelta\",\n",
    "                        optimizer_params={'rho': 0.9},\n",
    "                        scheduler=\"StepLR\",\n",
    "                        scheduler_params={'step_size':20, 'gamma':0.5},\n",
    "                        )\n",
    "\n",
    "                result, _ = run_cross_validation(\n",
    "                    model=model,\n",
    "                    dataset_folds=dataset,\n",
    "                    max_epochs=40,\n",
    "                    experiment_name=f\"BAE adj4 tuning {dataset[0]['train'].name} {hidden_size}\",\n",
    "                    run_name=f\"lr={initial_lr}\",\n",
    "                    save_model=False,\n",
    "                    fit_params={'adjust_epochs': True},\n",
    "                )\n",
    "    \n",
    "                logger.log(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
