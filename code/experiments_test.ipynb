{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('./datasets')\n",
    "sys.path.append('./models')\n",
    "\n",
    "from UNSW_NB15 import UNSWNB15Dataset\n",
    "from KDDCUP99 import KDDCUP99Dataset\n",
    "from CICIDS2017 import CICIDS2017Dataset\n",
    "\n",
    "from StandardAE import StandardAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median').set_output(transform='pandas')),\n",
    "    ('scaler', StandardScaler().set_output(transform='pandas'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded train data with 912188 samples.\n",
      "Data shape: (912188, 125)\n",
      "num_anomalies: 0\n",
      "num_normal: 912188\n",
      "anomaly ratio: 0.0\n",
      "\n",
      "Loaded val data with 311029 samples.\n",
      "Data shape: (311029, 125)\n",
      "num_anomalies: 250436\n",
      "num_normal: 60593\n",
      "anomaly ratio: 0.8051853685669182\n",
      "\n",
      "Loaded test data with 311029 samples.\n",
      "Data shape: (311029, 125)\n",
      "num_anomalies: 250436\n",
      "num_normal: 60593\n",
      "anomaly ratio: 0.8051853685669182\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data/KDDCUP99/preprocessed\")\n",
    "KDDCUP99 = {\n",
    "    'train' : KDDCUP99Dataset(data_dir, type = \"train\", transformer = pipeline),\n",
    "    'val' : KDDCUP99Dataset(data_dir, type = \"val\", transformer = pipeline),\n",
    "    'test' : KDDCUP99Dataset(data_dir, type = \"test\", transformer = pipeline)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded train data with 1715451 samples.\n",
      "Data shape: (1715451, 80)\n",
      "num_anomalies: 0\n",
      "num_normal: 1715451\n",
      "anomaly ratio: 0.0\n",
      "columns with missing values:\n",
      "['Flow Bytes/s', 'Flow Packets/s']\n",
      "columns with infinity values:\n",
      "[]\n",
      "\n",
      "Loaded val data with 557646 samples.\n",
      "Data shape: (557646, 80)\n",
      "num_anomalies: 278823\n",
      "num_normal: 278823\n",
      "anomaly ratio: 0.5\n",
      "columns with missing values:\n",
      "['Flow Bytes/s', 'Flow Packets/s']\n",
      "columns with infinity values:\n",
      "[]\n",
      "\n",
      "Loaded test data with 557646 samples.\n",
      "Data shape: (557646, 80)\n",
      "num_anomalies: 278823\n",
      "num_normal: 278823\n",
      "anomaly ratio: 0.5\n",
      "columns with missing values:\n",
      "['Flow Bytes/s', 'Flow Packets/s']\n",
      "columns with infinity values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data/CIC-IDS2017/preprocessed\")\n",
    "CICIDS2017 = {\n",
    "    'train' : CICIDS2017Dataset(data_dir, type = \"train\", transformer = pipeline),\n",
    "    'val' : CICIDS2017Dataset(data_dir, type = \"val\", transformer = pipeline),\n",
    "    'test' : CICIDS2017Dataset(data_dir, type = \"test\", transformer = pipeline)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded train data with 46000 samples.\n",
      "Data shape: (46000, 196)\n",
      "num_anomalies: 0\n",
      "num_normal: 46000\n",
      "anomaly ratio: 0.0\n",
      "\n",
      "Loaded val data with 22252 samples.\n",
      "Data shape: (22252, 196)\n",
      "num_anomalies: 12252\n",
      "num_normal: 10000\n",
      "anomaly ratio: 0.5506021930612979\n",
      "\n",
      "Loaded test data with 82332 samples.\n",
      "Data shape: (82332, 196)\n",
      "num_anomalies: 45332\n",
      "num_normal: 37000\n",
      "anomaly ratio: 0.5506000097167566\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data/UNSW-NB15/preprocessed\")\n",
    "UNSWNB15 = {\n",
    "    'train' : UNSWNB15Dataset(data_dir, type = \"train\", transformer = pipeline),\n",
    "    'val' : UNSWNB15Dataset(data_dir, type = \"val\", transformer = pipeline),\n",
    "    'test' : UNSWNB15Dataset(data_dir, type = \"test\", transformer = pipeline)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, \n",
    "                   dataset,\n",
    "                   max_epochs=10,\n",
    "                   experiment_name=\"undefined\",\n",
    "                   run_name=\"undefined\",\n",
    "                   dataset_name=\"undefined\",\n",
    "                   save_model=False):\n",
    "\n",
    "    model.set_tech_params(\n",
    "        accelerator='gpu',\n",
    "        batch_size=1024, \n",
    "        num_workers=1, \n",
    "        persistent_workers=False\n",
    "    )\n",
    "\n",
    "    model.fit(dataset['train'], dataset['val'], max_epochs=max_epochs, log=True, \n",
    "                        logger_params = {\n",
    "                                \"experiment_name\": experiment_name,\n",
    "                                \"run_name\": run_name,\n",
    "                                \"log_model\": False,\n",
    "                                \"tags\": {\"dataset\": dataset_name},\n",
    "                        })\n",
    "    \n",
    "    if save_model:\n",
    "        save_dir = Path(f\"../saved_models/{experiment_name}/{run_name}\")\n",
    "        file_name = f\"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{model.__class__.__name__}\"\n",
    "        file_num = 0\n",
    "        while (save_dir / f\"{file_name}_{file_num}.pt\").exists():\n",
    "            file_num += 1\n",
    "\n",
    "        model.save(save_dir / f\"{file_name}_{file_num}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Experiment with name IADModel test not found. Creating it.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | encoder | Sequential | 29.4 K | train\n",
      "1 | decoder | Sequential | 29.5 K | train\n",
      "-----------------------------------------------\n",
      "58.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.9 K    Total params\n",
      "0.236     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d106e54e987749c3a703b2a9515bdba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd8775754424e0a933df37c99e1e1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ce140b256444df95534d76fbbca299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "UNSWNB15_input_size = UNSWNB15['train'][0][0].shape[0]\n",
    "\n",
    "IStandardAE_model = StandardAE(input_size=UNSWNB15_input_size, \n",
    "                                hidden_sizes=[128,32, 8], \n",
    "                                dropout=False, \n",
    "                                initial_lr=2e-3, \n",
    "                                linear_lr_start_factor=1, \n",
    "                                linear_lr_end_factor=0.03, \n",
    "                                linear_lr_total_iters=25)\n",
    "\n",
    "run_experiment(model=IStandardAE_model,\n",
    "                dataset=UNSWNB15,\n",
    "                max_epochs=1,\n",
    "                experiment_name=\"IADModel test\",\n",
    "                run_name=\"run_experiment test\",\n",
    "                dataset_name=\"UNSW-NB15\",\n",
    "                save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = IStandardAE_model.predict_raw(UNSWNB15['val'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
